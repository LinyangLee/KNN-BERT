#!/bin/bash

CUDA_VISIBLE_DEVICES=0,1 python run_main.py --model_name_or_path roberta-large  --output_dir ./model/mrpc/  --do_eval --do_train  --task_name mrpc  --num_train_epochs 10  --per_device_eval_batch_size 16  --logging_steps 100 --save_steps 0 --overwrite_output_dir  --evaluation_strategy epoch --per_device_train_batch_size 16 --contrastive_rate_in_training 0.1  --learning_rate 2e-5 --contrastive_rate_in_inference 0.25 --load_model_pattern knn_bert --queue_size 48000 --top_k 50 --end_k 10 --task mrpc_knn --fitlog_dir ./logs

CUDA_VISIBLE_DEVICES=0,1 python run_main.py --model_name_or_path roberta-large  --output_dir ./model/qnli/  --do_eval --do_train  --task_name qnli  --num_train_epochs 10  --per_device_eval_batch_size 16  --logging_steps 100 --save_steps 0 --overwrite_output_dir  --evaluation_strategy epoch --per_device_train_batch_size 16 --contrastive_rate_in_training 0.1  --learning_rate 2e-5 --contrastive_rate_in_inference 0.25 --load_model_pattern knn_bert --queue_size 100000 --top_k 50 --end_k 10 --task qnli_knn --fitlog_dir ./logs

CUDA_VISIBLE_DEVICES=0,1 python run_main.py --model_name_or_path roberta-large  --output_dir ./model/sst2/  --do_eval --do_train  --task_name sst2  --num_train_epochs 10  --per_device_eval_batch_size 16  --logging_steps 100 --save_steps 0 --overwrite_output_dir  --evaluation_strategy epoch --per_device_train_batch_size 16 --contrastive_rate_in_training 0.1  --learning_rate 2e-5 --contrastive_rate_in_inference 0.25 --load_model_pattern knn_bert --queue_size 63000 --top_k 50 --end_k 10 --task sst2_knn --fitlog_dir ./logs
